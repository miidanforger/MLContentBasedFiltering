# -*- coding: utf-8 -*-
"""MLTProyekAkhir.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jqPJnAzE0xvr5laRtbqmyli0SZklr92p

# Content Based Filtering

## Import Libraries
"""

!pip install opendatasets

import pandas as pd
import numpy as np
import time
import opendatasets as od
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.metrics.pairwise import euclidean_distances

"""## Download Dataset"""

od.download("https://www.kaggle.com/datasets/thedevastator/adidas-fashion-retail-products-dataset-9300-prod")

"""## Univariate Exploratory Data Analysis

### Adidas Product Variabel
"""

df_adidas = pd.read_csv("/content/adidas-fashion-retail-products-dataset-9300-prod/adidas_usa.csv")
df_adidas.head()

df_adidas.describe()

print('Jumlah Produk Adidas: ', len(df_adidas.name.unique()))
print('Jumlah Kategori : ', len(df_adidas.category.unique()))
print('Jumlah Sub Kategori (breadcrumbs) : ', len(df_adidas.breadcrumbs.unique()))

"""## Data Preprocessing

### Menentukan fitur yang akan digunakan

Fitur yang akan digunakan adalah name, sku dan breadcrumbs. Pada kasus ini kita lebih mengutamakan penggunaan breadcrumbs daripada category karena memiliki nilai yang lebih variatif.
"""

adidass = df_adidas[["sku", "name", "breadcrumbs"]]
adidass.head()

"""## Data Preparation

### Mengatasi Missing Value
"""

adidass.isnull().sum()

adidass.isna().sum()

"""Dari output di atas, terlihat bahwa tidak ada *missing value* pada dataset.

## Model Development dengan Content Based Filtering

### TF-IDF Vectorizer
"""

# Inisialisasi TfidfVectorizer
tf = TfidfVectorizer()

# Melakukan perhitungan idf pada data adidas
tf.fit(adidass['breadcrumbs']) 
 
# Mapping array dari fitur index integer ke fitur nama
tf.get_feature_names()

# Melakukan fit lalu ditransformasikan ke bentuk matrix
tfidf_matrix = tf.fit_transform(adidass['breadcrumbs']) 
 
# Melihat ukuran matrix tfidf
tfidf_matrix.shape

# Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()
tfidf_matrix.todense()

# Membuat dataframe untuk melihat tf-idf matrix
 
pd.DataFrame(
    tfidf_matrix.todense(), 
    columns=tf.get_feature_names(),
    index=adidass.name
).sample(10, axis=1).sample(5, axis=0)

"""### Cosine Similarity

"""

def cosine_sim_handler(df_tfidf, series_title):
  # Menghitung cosine similarity pada dataframe tfidf
  cosine_sim = cosine_similarity(df_tfidf)

  # Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa nama produk
  df_cosine_sim = pd.DataFrame(cosine_sim, index=series_title, columns=series_title)

  # Melihat similarity matrix pada setiap produk
  return df_cosine_sim

# Menghitung cosine similarity pada matrix tf-idf
start = time.time()
cosine_sim_df = cosine_sim_handler(tfidf_matrix, adidass['name'])
cosine_exec_time = time.time() - start
print("Exec Time Cosine Similarity (Seconds) :", cosine_exec_time)

# Melihat similarity matrix pada setiap produk
print('Shape:', cosine_sim_df.shape)
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""### Euclidean Distance"""

def euclidean_sim_handler(df_tfidf, series_title):
  # Menghitung euclidean distance pada dataframe tfidf
  euclidean_dist = euclidean_distances(df_tfidf)

  # Menghitung euclidean similarity
  # Ref: https://stackoverflow.com/a/35216364
  f = lambda x: 1 / (1 + x)
  euclidean_sim = f(euclidean_dist)

  # Membuat dataframe dari variabel euclidean_sim dengan baris dan kolom berupa nama produk
  df_euclidean_sim = pd.DataFrame(euclidean_sim, index=series_title, columns=series_title)

  # Melihat similarity matrix pada setiap produk
  return df_euclidean_sim

start = time.time()
euclidean_sim_df = euclidean_sim_handler(tfidf_matrix, adidass["name"])
euclidean_exec_time = time.time() - start
print("Exec Time Euclidean Similarity (Seconds) :", euclidean_exec_time)

print('Shape:', euclidean_sim_df.shape)
euclidean_sim_df.sample(5, axis=1).sample(10, axis=0)

"""### Mendapatkan Rekomendasi"""

def product_recommendations(nama_produk, similarity_data, items=adidass, k=10):
 
    # Mengambil data dengan menggunakan argpartition untuk melakukan partisi secara tidak langsung sepanjang sumbu yang diberikan    
    # Dataframe diubah menjadi numpy
    # Range(start, stop, step)
    index = similarity_data.loc[:,nama_produk].to_numpy().argpartition(
        range(-1, -k, -1)) # Ngambil 10 data terakhir setelah diurutkan dari kecil sampai besar
    
    # Mengambil data dengan similarity terbesar dari index yang ada
    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    
    # Drop nama_produk agar nama produk yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(nama_produk, errors='ignore')
 
    return pd.DataFrame(closest).merge(items).head(k)

adidass[adidass["name"].eq('Real Madrid Tee')]

"""#### Rekomendasi dengan Cosine Similarity"""

product_recommendations(
    nama_produk="Real Madrid Tee",
    similarity_data=cosine_sim_df
)

"""#### Rekomendasi dengan Euclidean Distance"""

product_recommendations(
    nama_produk="Real Madrid Tee",
    similarity_data=euclidean_sim_df
)

"""## Evaluasi

$$\text{Recommender system precision (P)} = \frac{\text{#of our recommendation that relevant}}{\text{#of item we recommend}}\times 100% $$

Dari hasil rekomendasi di atas, dapat diketahui bahwa `Real Madrid Tee` termasuk ke dalam kategori (breadcrumbs) `Kids/Clothing`. Dari 10 produk yang direkomendasikan, berikut nilai _precision_ pada model _cosine similarity_ dan _euclidean distance_.
 
|Model | Sesuai | Tidak Sesuai |Total| Precision |
|---|---|---|---|---|
|_Cosine Similarity_|10|0|10|100%|
|_Euclidean Similarity_|10|0|10|100%|
 
Pada tabel di atas, terlihat bahwa model *Cosine Similiarity* dan *Euclidean Distance* memiliki nilai _precision_ yang sama pada top-10 rekomendasi di atas.

Selain dari nilai _precision_, lama komputasi setiap metode juga perlu dipertimbangkan. Berikut perbandingannya:
"""

df_exec_time_models = pd.DataFrame(index=['Time (Seconds)'],
    columns=['Cosine Similarity', 'Euclidean Similarity'])

df_exec_time_models['Cosine Similarity'] = [cosine_exec_time]
df_exec_time_models['Euclidean Similarity'] = [euclidean_exec_time]

df_exec_time_models

"""Berdasarkan output di atas, waktu komputasi pada metode Cosine Similarity (0.019989 detik) lebih cepat dibandingkan Euclidean Similarity (0.029959 detik).

## Data Diri

- Muhamad Dani
- M346X0902
- M06
"""